{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3896e7b2",
   "metadata": {},
   "source": [
    "# Categorizing zoo animal species by microbiome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb1f0f",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "### 1.1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc7b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Turn only off for presentation purposes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fdb337",
   "metadata": {},
   "source": [
    "### 1.2 Data import\n",
    "Data has been preprocessed in R. We removed all animal species with less than 20 probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372916e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "df = pd.read_csv('data/data_clean.csv')\n",
    "metadata = df.iloc[:,:9].drop_duplicates().sort_values(['Familie','Gattung','Art']).reset_index(drop=True)\n",
    "metadata_familie = metadata[['Familie','Diet','digestion']].drop_duplicates().reset_index(drop=True)\n",
    "metadata_gattung = metadata[['Gattung','Diet','digestion']].drop_duplicates().reset_index(drop=True)\n",
    "# Identifying zoo and individuals from index name\n",
    "df.insert(0, 'Zoo', df['index'].str[:3])\n",
    "df.insert(1, 'AnimalID', df['index'].str[7:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3da15",
   "metadata": {},
   "source": [
    "### 1.3 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e22e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_test_split(df, y_name=\"\", test_size=0.2, random_state=42):\n",
    "    if y_name != \"\":\n",
    "        # Check if stratification is possible\n",
    "        can_stratify = df[y_name].value_counts().min() > 1\n",
    "        \n",
    "        # If stratification is possible, use it\n",
    "        if can_stratify:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size/(1-test_size), \n",
    "                random_state=random_state, stratify=df[y_name]\n",
    "            )\n",
    "        # If not, do a simple split without stratification\n",
    "        else:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size/(1-test_size), \n",
    "                random_state=random_state\n",
    "            )\n",
    "        \n",
    "        # Define input and output variables\n",
    "        X_train = train.iloc[:,12:]\n",
    "        if y_name != 'Art':\n",
    "            X_train = X_train.drop([y_name], axis=1)\n",
    "        y_train = train[y_name]\n",
    "\n",
    "        X_test = test.iloc[:,12:]\n",
    "        if y_name != 'Art':\n",
    "            X_test = X_test.drop([y_name], axis=1)\n",
    "        y_test = test[y_name]\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    else:\n",
    "        # Check if stratification is possible\n",
    "        can_stratify = df['Art'].value_counts().min() > 1\n",
    "        \n",
    "        # If stratification is possible, use it\n",
    "        if can_stratify:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size, \n",
    "                random_state=random_state, stratify=df['Art']\n",
    "            )\n",
    "        # If not, do a simple split without stratification\n",
    "        else:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size, \n",
    "                random_state=random_state\n",
    "            )\n",
    "        \n",
    "        return train, test\n",
    "\n",
    "# One-hot encoded data\n",
    "def one_hot_encoding(df, Art):\n",
    "    # One-hot encoding of column\n",
    "    df_Art = pd.get_dummies(df.Art)\n",
    "    # Join with dummy data\n",
    "    df_tmp = df.iloc[:,:-1].join(df_Art[Art])\n",
    "    # Split data\n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = train_dev_test_split(df_tmp, Art)\n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test\n",
    "\n",
    "# Find best parameters using GridSearchCV for logistic regression\n",
    "def lr_best_model(X_train, y_train):\n",
    "    # Define multiple hyperparameter grids to search over\n",
    "    param_grids = [\n",
    "        {\n",
    "            'penalty': ['l1', 'l2'],  # l1 and l2 penalties\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'solver': ['liblinear'],  # liblinear supports l1 and l2\n",
    "            'max_iter': [100, 500, 1000],\n",
    "        },\n",
    "        {\n",
    "            'penalty': ['l2', 'none'],  # l2 and none penalties\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'solver': ['newton-cg', 'lbfgs', 'sag'],  # these solvers support l2 and none\n",
    "            'max_iter': [100, 500, 1000],\n",
    "        },\n",
    "        {\n",
    "            'penalty': ['l1', 'l2', 'none'],  # l1, l2 and none penalties\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'solver': ['saga'],  # saga supports l1, l2, and none\n",
    "            'max_iter': [100, 500, 1000],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Create a logistic regression model\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "\n",
    "    # Perform grid search over the hyperparameter grids using 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=lr,\n",
    "                               param_grid=param_grids,\n",
    "                               cv=5,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "    # Fit the grid search to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and best score\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best score: {grid_search.best_score_}\")\n",
    "    \n",
    "    return grid_search.best_params_\n",
    "\n",
    "def train_best_model(X_train, y_train, params):\n",
    "    # Create a new logistic regression model with the best hyperparameters\n",
    "    best_lr = LogisticRegression(**params, random_state=42)\n",
    "\n",
    "    # Fit the new model to the training data\n",
    "    best_lr.fit(X_train, y_train)\n",
    "    \n",
    "    return best_lr\n",
    "\n",
    "def evaluate_model(best_lr, X_dev, y_dev):\n",
    "    # Evaluate the performance of the new model on the test data\n",
    "    score = best_lr.score(X_dev, y_dev)\n",
    "    print(f\"Test score: {score}\")\n",
    "\n",
    "    # Print the results\n",
    "    y_pred = best_lr.predict(X_dev)\n",
    "    print(classification_report(y_dev, y_pred))\n",
    "\n",
    "    # Create the confusion matrix\n",
    "    cm = confusion_matrix(y_dev, y_pred)\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    \n",
    "def best_lr(df, Art):\n",
    "    # One-hot encoding\n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = one_hot_encoding(df, Art)\n",
    "    # Best params\n",
    "    params = lr_best_model(X_train, y_train)\n",
    "    # Best model\n",
    "    best_lr = train_best_model(X_train, y_train, params)\n",
    "    # Evaluate model\n",
    "    evaluate_model(best_lr, X_dev, y_dev)\n",
    "    \n",
    "    return best_lr\n",
    "\n",
    "# Trains logistic regression based on specific attribute\n",
    "def categorize_attribute(df, df_attribute, attribute):\n",
    "    # Join with dummy data\n",
    "    df_tmp = df.join(df_attribute[attribute])\n",
    "    # Split data\n",
    "    X_train, y_train, X_dev, y_dev = train_dev_test_split(df_tmp, attribute)\n",
    "    # Best params\n",
    "    params = lr_best_model(X_train, y_train)\n",
    "    # Best model\n",
    "    lr = train_best_model(X_train, y_train, params)\n",
    "    # Evaluate model\n",
    "    evaluate_model(lr, X_dev, y_dev)\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15684cdf",
   "metadata": {},
   "source": [
    "## 2. Modelling - Logistic Regression\n",
    "### 2.1 Preparing training and development sets\n",
    "We split the dataset into training & development and test sets and put the test set aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8626f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dev, df_test = train_dev_test_split(df.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322eb60",
   "metadata": {},
   "source": [
    "### 2.2 Classification by diet\n",
    "A second approach is to classify by diet first and then build up subsequent models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a4d03",
   "metadata": {},
   "source": [
    "#### 2.2.1 Herbivore vs. carnivore and omnivore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4285bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1.0, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best score: 0.9746031746031747\n",
      "Test score: 0.9809523809523809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        57\n",
      "           1       0.98      0.98      0.98        48\n",
      "\n",
      "    accuracy                           0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n",
      "Confusion Matrix:\n",
      " [[56  1]\n",
      " [ 1 47]]\n"
     ]
    }
   ],
   "source": [
    "# Add herbivore dummy\n",
    "df_train_dev['Herbivore'] = (df_train_dev['Diet'] == 'herbivor').astype(int)\n",
    "# Train and dev data\n",
    "X_train, y_train, X_dev, y_dev = train_dev_test_split(df_train_dev, 'Herbivore')\n",
    "# Best params\n",
    "params = lr_best_model(X_train, y_train)\n",
    "# Best model\n",
    "lr_herbivore = train_best_model(X_train, y_train, params)\n",
    "# Evaluate model\n",
    "evaluate_model(lr_herbivore, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57587c79",
   "metadata": {},
   "source": [
    "The results are quite good and promising to move further with this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c05ecb",
   "metadata": {},
   "source": [
    "#### 2.2.2 Carnivore vs. omnivore\n",
    "Given that we distinguished herbivores from other diets, we now want to differentiate between carnivores and omnivores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e12a13fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "Best score: 0.8309243697478992\n",
      "Test score: 0.8620689655172413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83        21\n",
      "           1       0.97      0.81      0.88        37\n",
      "\n",
      "    accuracy                           0.86        58\n",
      "   macro avg       0.85      0.88      0.86        58\n",
      "weighted avg       0.89      0.86      0.86        58\n",
      "\n",
      "Confusion Matrix:\n",
      " [[20  1]\n",
      " [ 7 30]]\n"
     ]
    }
   ],
   "source": [
    "# Filter df for carnivores and omnivors\n",
    "df_carni_omni = df_train_dev[df_train_dev.Diet != 'herbivor']\n",
    "df_carni_omni = df_carni_omni.drop('Herbivore', axis=1)\n",
    "df_carni_omni['Carnivore'] = (df['Diet'] == 'carnivor').astype(int)\n",
    "# Train and dev data\n",
    "X_train, y_train, X_dev, y_dev = train_dev_test_split(df_carni_omni, 'Carnivore')\n",
    "# Best params\n",
    "params = lr_best_model(X_train, y_train)\n",
    "# Best model\n",
    "lr_carnivore = train_best_model(X_train, y_train, params)\n",
    "# Evaluate model\n",
    "evaluate_model(lr_carnivore, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5edee07",
   "metadata": {},
   "source": [
    "The results are not as good as the herbivore model but still good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155acddb",
   "metadata": {},
   "source": [
    "### 2.3 Classification of family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cff4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding of animal family\n",
    "df_family = pd.get_dummies(df_train_dev.Familie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec94700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##herbivor############################################################\n",
      "##Ailuridae############################################################\n",
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 1.0\n",
      "Test score: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00        42\n",
      "        True       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  0]\n",
      " [ 0  6]]\n",
      "##Bovidae############################################################\n",
      "Best parameters: {'C': 100.0, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best score: 0.9362068965517241\n",
      "Test score: 0.9791666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.96      0.98        28\n",
      "        True       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.98        48\n",
      "   macro avg       0.98      0.98      0.98        48\n",
      "weighted avg       0.98      0.98      0.98        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27  1]\n",
      " [ 0 20]]\n",
      "##Equidae############################################################\n",
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 0.9859605911330049\n",
      "Test score: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00        31\n",
      "        True       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[31  0]\n",
      " [ 0 17]]\n",
      "##Giraffidae############################################################\n",
      "Best parameters: {'C': 10.0, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best score: 0.9443349753694582\n",
      "Test score: 0.9791666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      1.00      0.99        42\n",
      "        True       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.98        48\n",
      "   macro avg       0.99      0.92      0.95        48\n",
      "weighted avg       0.98      0.98      0.98        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  0]\n",
      " [ 1  5]]\n",
      "##Canidae############################################################\n",
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best score: nan\n",
      "Test score: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00        48\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[48]]\n",
      "##omnivor############################################################\n",
      "##Ursidae############################################################\n",
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "Best score: 0.9333333333333333\n",
      "Test score: 0.9523809523809523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.88      0.93         8\n",
      "        True       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.96      0.94      0.95        21\n",
      "weighted avg       0.96      0.95      0.95        21\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7  1]\n",
      " [ 0 13]]\n",
      "##Herpestidae############################################################\n",
      "Best parameters: {'C': 10.0, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best score: 0.9679487179487178\n",
      "Test score: 0.9047619047619048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.94      0.94        17\n",
      "        True       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.85      0.85      0.85        21\n",
      "weighted avg       0.90      0.90      0.90        21\n",
      "\n",
      "Confusion Matrix:\n",
      " [[16  1]\n",
      " [ 1  3]]\n",
      "##Canidae############################################################\n",
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'none', 'solver': 'sag'}\n",
      "Best score: 0.9525641025641025\n",
      "Test score: 0.8571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.88      0.91        17\n",
      "        True       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.86        21\n",
      "   macro avg       0.77      0.82      0.79        21\n",
      "weighted avg       0.87      0.86      0.86        21\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15  2]\n",
      " [ 1  3]]\n",
      "##carnivor############################################################\n",
      "##Canidae############################################################\n",
      "Best parameters: {'C': 0.01, 'max_iter': 1000, 'penalty': 'none', 'solver': 'sag'}\n",
      "Best score: 0.8478260869565217\n",
      "Test score: 0.7567567567567568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.79      0.83        28\n",
      "        True       0.50      0.67      0.57         9\n",
      "\n",
      "    accuracy                           0.76        37\n",
      "   macro avg       0.69      0.73      0.70        37\n",
      "weighted avg       0.79      0.76      0.77        37\n",
      "\n",
      "Confusion Matrix:\n",
      " [[22  6]\n",
      " [ 3  6]]\n",
      "##Felidae############################################################\n",
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'none', 'solver': 'sag'}\n",
      "Best score: 0.8462450592885375\n",
      "Test score: 0.8648648648648649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.80      0.76        10\n",
      "        True       0.92      0.89      0.91        27\n",
      "\n",
      "    accuracy                           0.86        37\n",
      "   macro avg       0.83      0.84      0.83        37\n",
      "weighted avg       0.87      0.86      0.87        37\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 8  2]\n",
      " [ 3 24]]\n"
     ]
    }
   ],
   "source": [
    "for diet in df_train_dev.Diet.unique():\n",
    "    print(2*'#'+diet+60*'#')\n",
    "    df_diet = df_train_dev[df_train_dev.Diet == diet]\n",
    "    df_family = pd.get_dummies(df_diet.Familie)\n",
    "    for family in df_diet.Familie.unique():\n",
    "        print(2*'#'+family+60*'#')\n",
    "        categorize_attribute(df_diet, df_family, family)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f685d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'none', 'solver': 'sag'}\n",
      "Best score: 0.8462450592885375\n",
      "Test score: 0.8648648648648649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.80      0.76        10\n",
      "        True       0.92      0.89      0.91        27\n",
      "\n",
      "    accuracy                           0.86        37\n",
      "   macro avg       0.83      0.84      0.83        37\n",
      "weighted avg       0.87      0.86      0.87        37\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 8  2]\n",
      " [ 3 24]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, penalty=&#x27;none&#x27;, random_state=42, solver=&#x27;sag&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, penalty=&#x27;none&#x27;, random_state=42, solver=&#x27;sag&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, penalty='none', random_state=42, solver='sag')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorize_attribute(df_diet, df_family, family) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9833ae6",
   "metadata": {},
   "source": [
    "### 3.3 Classification by digestion for herbivores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "656bfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter train dev dataset for herbivores only\n",
    "df_herbivore = df_train_dev[df_train_dev.Diet == 'herbivor'].drop('Herbivore', axis=1)\n",
    "# One-hot encoding of digestion\n",
    "df_digestion = pd.get_dummies(df_herbivore.digestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1e4df",
   "metadata": {},
   "source": [
    "#### 3.3.1 Classification by digestion for herbivores - Foregut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2cd27",
   "metadata": {},
   "source": [
    "#### 3.3.2 Classification by digestion for herbivores - Foregut ruminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30fa892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1.0, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best score: 0.9928571428571429\n",
      "Test score: 0.9583333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      1.00      0.96        23\n",
      "        True       1.00      0.92      0.96        25\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.96      0.96      0.96        48\n",
      "weighted avg       0.96      0.96      0.96        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[23  0]\n",
      " [ 2 23]]\n"
     ]
    }
   ],
   "source": [
    "lr_foregut_r = categorize_attribute(df_herbivore, df_digestion, 'foregut_ruminant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4b607",
   "metadata": {},
   "source": [
    "#### 3.3.3 Classification by digestion for herbivores - Hindgut caecum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba02f9d",
   "metadata": {},
   "source": [
    "#### 3.3.4 Classification by digestion for herbivores - Hindgut colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15fa9c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 0.9859605911330049\n",
      "Test score: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00        31\n",
      "        True       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[31  0]\n",
      " [ 0 17]]\n"
     ]
    }
   ],
   "source": [
    "lr_hindgut_co = categorize_attribute(df_herbivore, df_digestion, 'hindgut_colon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388182d",
   "metadata": {},
   "source": [
    "#### 3.3.5 Classification by digestion for herbivores -  Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cbcac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 1.0\n",
      "Test score: 0.9791666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      1.00      0.99        42\n",
      "        True       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.98        48\n",
      "   macro avg       0.99      0.92      0.95        48\n",
      "weighted avg       0.98      0.98      0.98        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  0]\n",
      " [ 1  5]]\n"
     ]
    }
   ],
   "source": [
    "lr_simple = categorize_attribute(df_herbivore, df_digestion, 'simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb7023",
   "metadata": {},
   "source": [
    "#### 3.3.6 Classification by digestion for herbivores -  Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e1b541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def herbivore_digestion_ensemble(x):\n",
    "    x = x.astype(float)\n",
    "    res = {'foregut' : lr_foregut.predict_proba([x.values])[0][1],\n",
    "           'foregut_ruminant' : lr_foregut_r.predict_proba([x.values])[0][1],\n",
    "           'hindgut_caecum' : lr_hindgut_ca.predict_proba([x.values])[0][1],\n",
    "           'hindgut_colon' : lr_hindgut_co.predict_proba([x.values])[0][1],\n",
    "           'simple' : lr_simple.predict_proba([x.values])[0][1]\n",
    "          }\n",
    "    \n",
    "    max_key = max(res, key=lambda k: res[k])\n",
    "    \n",
    "    return max_key\n",
    "\n",
    "#df_herbivore.iloc[:,9:].apply(digestion_prediction, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50c1b11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Diet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digestion</th>\n",
       "      <th>Familie</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">foregut_ruminant</th>\n",
       "      <th>Bovidae</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Giraffidae</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hindgut_colon</th>\n",
       "      <th>Equidae</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">simple</th>\n",
       "      <th>Ailuridae</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canidae</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Diet\n",
       "digestion        Familie         \n",
       "foregut_ruminant Bovidae       78\n",
       "                 Giraffidae    22\n",
       "hindgut_colon    Equidae       66\n",
       "simple           Ailuridae     23\n",
       "                 Canidae        1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_herbivore[['digestion','Familie','Diet']].groupby(['digestion','Familie']).count()#.sort_values('Diet', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63c8ef",
   "metadata": {},
   "source": [
    "### 3.4 Classification of animal family given diet and digestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671435a9",
   "metadata": {},
   "source": [
    "#### 3.4.1 Herbivore and foregut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29f30735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Familie - Foregut\n",
    "df_herb_fg = df_train_dev[(df_train_dev.Diet == 'herbivor') & (df_train_dev.digestion == 'foregut')]\n",
    "# One-hot encoding of digestion\n",
    "df_herb_fg_familie = pd.get_dummies(df_herb_fg.Familie)\n",
    "\n",
    "# Funktioniert nicht, weil zu wenig Beobachtungen:\n",
    "#lr_Hippopotamidae = categorize_attribute(df_herb_fg, df_herb_fg_familie, 'Hippopotamidae')\n",
    "#lr_Macropodidae = categorize_attribute(df_herb_fg, df_herb_fg_familie, 'Macropodidae')\n",
    "#lr_Suidae = categorize_attribute(df_herb_fg, df_herb_fg_familie, 'Suidae')\n",
    "#lr_Tapiridae = categorize_attribute(df_herb_fg, df_herb_fg_familie, 'Tapiridae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba96f4",
   "metadata": {},
   "source": [
    "#### 3.4.2 Herbivore and foregut ruminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "990238c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Bovidae\n",
      "--------------------------------------------------------------------------------\n",
      "Best parameters: {'C': 1.0, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best score: 0.9333333333333333\n",
      "Test score: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.83      0.91         6\n",
      "        True       0.95      1.00      0.97        19\n",
      "\n",
      "    accuracy                           0.96        25\n",
      "   macro avg       0.97      0.92      0.94        25\n",
      "weighted avg       0.96      0.96      0.96        25\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 5  1]\n",
      " [ 0 19]]\n",
      "--------------------------------------------------------------------------------\n",
      "Giraffidae\n",
      "--------------------------------------------------------------------------------\n",
      "Best parameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 0.8933333333333333\n",
      "Test score: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00        20\n",
      "        True       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "Confusion Matrix:\n",
      " [[20  0]\n",
      " [ 0  5]]\n"
     ]
    }
   ],
   "source": [
    "# Familie - Foregut ruminant\n",
    "df_herb_fg_r = df_train_dev[(df_train_dev.Diet == 'herbivor') & (df_train_dev.digestion == 'foregut_ruminant')]\n",
    "# One-hot encoding of digestion\n",
    "df_herb_fg_r_familie = pd.get_dummies(df_herb_fg_r.Familie)\n",
    "\n",
    "# Create model for each family\n",
    "print('-' * 80 + \"\\nBovidae\\n\" + '-' * 80)\n",
    "lr_Bovidae = categorize_attribute(df_herb_fg_r, df_herb_fg_r_familie, 'Bovidae')\n",
    "#print('-' * 80 + \"\\nCamelidae\\n\" + '-' * 80)\n",
    "#lr_Camelidae = categorize_attribute(df_herb_fg_r, df_herb_fg_r_familie, 'Camelidae')\n",
    "#print('-' * 80 + \"\\nCervidae\\n\" + '-' * 80)\n",
    "#lr_Cervidae = categorize_attribute(df_herb_fg_r, df_herb_fg_r_familie, 'Cervidae')\n",
    "print('-' * 80 + \"\\nGiraffidae\\n\" + '-' * 80)\n",
    "lr_Giraffidae = categorize_attribute(df_herb_fg_r, df_herb_fg_r_familie, 'Giraffidae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d70879",
   "metadata": {},
   "source": [
    "#### 3.4.3 Herbivore and hindgut colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "754b0a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Equidae\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 825 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n150 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1227, in fit\n    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n                                                ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1179, in _fit_liblinear\n    raise ValueError(\nValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: True\n\n--------------------------------------------------------------------------------\n675 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1252, in fit\n    raise ValueError(\nValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create model for each family\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#print('-' * 80 + \"\\nElephantidae\\n\" + '-' * 80)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#lr_Elephantidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Elephantidae')\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEquidae\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m lr_Equidae \u001b[38;5;241m=\u001b[39m categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEquidae\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 146\u001b[0m, in \u001b[0;36mcategorize_attribute\u001b[1;34m(df, df_attribute, attribute)\u001b[0m\n\u001b[0;32m    144\u001b[0m X_train, y_train, X_dev, y_dev \u001b[38;5;241m=\u001b[39m train_dev_test_split(df_tmp, attribute)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Best params\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m params \u001b[38;5;241m=\u001b[39m lr_best_model(X_train, y_train)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Best model\u001b[39;00m\n\u001b[0;32m    148\u001b[0m lr \u001b[38;5;241m=\u001b[39m train_best_model(X_train, y_train, params)\n",
      "Cell \u001b[1;32mIn[3], line 95\u001b[0m, in \u001b[0;36mlr_best_model\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m     89\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m     90\u001b[0m                            param_grid\u001b[38;5;241m=\u001b[39mparam_grids,\n\u001b[0;32m     91\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     92\u001b[0m                            n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Fit the grid search to the training data\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Print the best parameters and best score\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 825 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n150 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1227, in fit\n    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n                                                ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1179, in _fit_liblinear\n    raise ValueError(\nValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: True\n\n--------------------------------------------------------------------------------\n675 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dmont\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1252, in fit\n    raise ValueError(\nValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: True\n"
     ]
    }
   ],
   "source": [
    "# Familie - Hingut colon\n",
    "df_herb_hg_co = df_train_dev[(df_train_dev.Diet == 'herbivor') & (df_train_dev.digestion == 'hindgut_colon')]\n",
    "# One-hot encoding of digestion\n",
    "df_herb_hg_co_familie = pd.get_dummies(df_herb_hg_co.Familie)\n",
    "\n",
    "# Create model for each family\n",
    "#print('-' * 80 + \"\\nElephantidae\\n\" + '-' * 80)\n",
    "#lr_Elephantidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Elephantidae')\n",
    "print('-' * 80 + \"\\nEquidae\\n\" + '-' * 80)\n",
    "lr_Equidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Equidae')\n",
    "#print('-' * 80 + \"\\nPhascolarctidae\\n\" + '-' * 80)\n",
    "#lr_Phascolarctidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Phascolarctidae')\n",
    "#print('-' * 80 + \"\\nRhinocerotidae\\n\" + '-' * 80)\n",
    "#lr_Rhinocerotidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Rhinocerotidae')\n",
    "#print('-' * 80 + \"\\nVombatidae\\n\" + '-' * 80)\n",
    "#lr_Vombatidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Vombatidae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa86cd",
   "metadata": {},
   "source": [
    "#### 3.4.4 Herbivore and simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Familie - Simple\n",
    "df_herb_simple = df_train_dev[(df_train_dev.Diet == 'herbivor') & (df_train_dev.digestion == 'simple')]\n",
    "# One-hot encoding of digestion\n",
    "df_herb_simple_familie = pd.get_dummies(df_herb_simple.Familie)\n",
    "\n",
    "# Create model for each family\n",
    "print('-' * 80 + \"\\nAiluridae\\n\" + '-' * 80)\n",
    "lr_Ailuridae = categorize_attribute(df_herb_simple, df_herb_simple_familie, 'Ailuridae')\n",
    "print('-' * 80 + \"\\nHomininae\\n\" + '-' * 80)\n",
    "lr_Homininae = categorize_attribute(df_herb_simple, df_herb_simple_familie, 'Homininae')\n",
    "print('-' * 80 + \"\\nLemuridae\\n\" + '-' * 80)\n",
    "lr_Lemuridae = categorize_attribute(df_herb_simple, df_herb_simple_familie, 'Lemuridae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718cf6cd",
   "metadata": {},
   "source": [
    "### 3.5 Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4290a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = df.Art.loc[X_dev.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7228c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foregut_ruminant(microbiome):\n",
    "    res = {'Bovidae' : lr_Bovidae.predict_proba(microbiome)[0][1],\n",
    "           'Camelidae' : lr_Camelidae.predict_proba(microbiome)[0][1],\n",
    "           'Cervidae' : lr_Cervidae.predict_proba(microbiome)[0][1],\n",
    "           'Giraffidae' : lr_Giraffidae.predict_proba(microbiome)[0][1]}\n",
    "    \n",
    "    max_key = max(res, key=lambda k: res[k])\n",
    "    \n",
    "    return max_key\n",
    "    \n",
    "\n",
    "def categorize_microbiome(microbiome):\n",
    "    res = []\n",
    "    # First, predict if herbivore or carni-/omnivore\n",
    "    diet = lr_herbivore.predict(microbiome)\n",
    "    # Second, based on diet predict type of digestion\n",
    "    for i in range(len(diet)):\n",
    "        if diet[i] == 1:\n",
    "            digestion = herbivore_digestion_ensemble(microbiome.iloc[i])\n",
    "            res.append()\n",
    "        else:\n",
    "            res.append(metadata_familie[(metadata_familie.Diet != 'herbivor')].Familie.drop_duplicates().to_list())\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[0,9:-1].astype(float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
