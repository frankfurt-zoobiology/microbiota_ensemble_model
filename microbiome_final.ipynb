{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3896e7b2",
   "metadata": {},
   "source": [
    "# Categorizing zoo animal species by microbiome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb1f0f",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "### 1.1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adc7b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Turn only off for presentation purposes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fdb337",
   "metadata": {},
   "source": [
    "### 1.2 Data import\n",
    "Data has been preprocessed in R. We removed all animal species with less than 20 probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372916e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "df = pd.read_csv('data/data_clean.csv')\n",
    "metadata = df.iloc[:,:9].drop_duplicates().sort_values(['Familie','Gattung','Art']).reset_index(drop=True)\n",
    "metadata_familie = metadata[['Familie','Diet','digestion']].drop_duplicates().reset_index(drop=True)\n",
    "metadata_gattung = metadata[['Gattung','Diet','digestion']].drop_duplicates().reset_index(drop=True)\n",
    "# Identifying zoo and individuals from index name\n",
    "df.insert(0, 'Zoo', df['index'].str[:3])\n",
    "df.insert(1, 'AnimalID', df['index'].str[7:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3da15",
   "metadata": {},
   "source": [
    "### 1.3 Function library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e22e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_test_split(df, y_name=\"\", test_size=0.2, random_state=42):\n",
    "    if y_name != \"\":\n",
    "        # Check if stratification is possible\n",
    "        can_stratify = df[y_name].value_counts().min() > 1\n",
    "        \n",
    "        # If stratification is possible, use it\n",
    "        if can_stratify:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size/(1-test_size), \n",
    "                random_state=random_state, stratify=df[y_name]\n",
    "            )\n",
    "        # If not, do a simple split without stratification\n",
    "        else:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size/(1-test_size), \n",
    "                random_state=random_state\n",
    "            )\n",
    "        \n",
    "        # Define input and output variables\n",
    "        X_train = train.iloc[:,12:]\n",
    "        if y_name != 'Art':\n",
    "            X_train = X_train.drop([y_name], axis=1)\n",
    "        y_train = train[y_name]\n",
    "\n",
    "        X_test = test.iloc[:,12:]\n",
    "        if y_name != 'Art':\n",
    "            X_test = X_test.drop([y_name], axis=1)\n",
    "        y_test = test[y_name]\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    else:\n",
    "        # Check if stratification is possible\n",
    "        can_stratify = df['Art'].value_counts().min() > 1\n",
    "        \n",
    "        # If stratification is possible, use it\n",
    "        if can_stratify:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size, \n",
    "                random_state=random_state, stratify=df['Art']\n",
    "            )\n",
    "        # If not, do a simple split without stratification\n",
    "        else:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size, \n",
    "                random_state=random_state\n",
    "            )\n",
    "        \n",
    "        return train, test\n",
    "\n",
    "# One-hot encoded data\n",
    "def one_hot_encoding(df, Art):\n",
    "    # One-hot encoding of column\n",
    "    df_Art = pd.get_dummies(df.Art)\n",
    "    # Join with dummy data\n",
    "    df_tmp = df.iloc[:,:-1].join(df_Art[Art])\n",
    "    # Split data\n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = train_dev_test_split(df_tmp, Art)\n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test\n",
    "\n",
    "# Find best parameters using GridSearchCV for logistic regression\n",
    "def lr_best_model(X_train, y_train):\n",
    "    # Define multiple hyperparameter grids to search over\n",
    "    param_grids = [\n",
    "        {\n",
    "            'penalty': ['l1', 'l2'],  # l1 and l2 penalties\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'solver': ['liblinear'],  # liblinear supports l1 and l2\n",
    "            'max_iter': [100, 500, 1000],\n",
    "        },\n",
    "        {\n",
    "            'penalty': ['l2', 'none'],  # l2 and none penalties\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'solver': ['newton-cg', 'lbfgs', 'sag'],  # these solvers support l2 and none\n",
    "            'max_iter': [100, 500, 1000],\n",
    "        },\n",
    "        {\n",
    "            'penalty': ['l1', 'l2', 'none'],  # l1, l2 and none penalties\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'solver': ['saga'],  # saga supports l1, l2, and none\n",
    "            'max_iter': [100, 500, 1000],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Create a logistic regression model\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "\n",
    "    # Perform grid search over the hyperparameter grids using 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=lr,\n",
    "                               param_grid=param_grids,\n",
    "                               cv=5,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "    # Fit the grid search to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and best score\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best score: {grid_search.best_score_}\")\n",
    "    \n",
    "    return grid_search.best_params_\n",
    "\n",
    "def train_best_model(X_train, y_train, params):\n",
    "    # Create a new logistic regression model with the best hyperparameters\n",
    "    best_lr = LogisticRegression(**params, random_state=42)\n",
    "\n",
    "    # Fit the new model to the training data\n",
    "    best_lr.fit(X_train, y_train)\n",
    "    \n",
    "    return best_lr\n",
    "\n",
    "def evaluate_model(best_lr, X_dev, y_dev):\n",
    "    # Evaluate the performance of the new model on the test data\n",
    "    score = best_lr.score(X_dev, y_dev)\n",
    "    print(f\"Test score: {score}\")\n",
    "\n",
    "    # Print the results\n",
    "    y_pred = best_lr.predict(X_dev)\n",
    "    print(classification_report(y_dev, y_pred))\n",
    "\n",
    "    # Create the confusion matrix\n",
    "    cm = confusion_matrix(y_dev, y_pred)\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_pred_proba = best_lr.predict_proba(X_dev)[:, 1]\n",
    "    # Calculate AUC\n",
    "    auc_score = roc_auc_score(y_dev, y_pred_proba)\n",
    "    print(f\"AUC: {auc_score}\")\n",
    "    \n",
    "def best_lr(df, Art):\n",
    "    # One-hot encoding\n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = one_hot_encoding(df, Art)\n",
    "    # Best params\n",
    "    params = lr_best_model(X_train, y_train)\n",
    "    # Best model\n",
    "    best_lr = train_best_model(X_train, y_train, params)\n",
    "    # Evaluate model\n",
    "    evaluate_model(best_lr, X_dev, y_dev)\n",
    "    \n",
    "    return best_lr\n",
    "\n",
    "# Trains logistic regression based on specific attribute\n",
    "def categorize_attribute(df, column, attribute):\n",
    "    # Get dummies\n",
    "    df_attribute = pd.get_dummies(df[column])\n",
    "    # Join with dummy data\n",
    "    df_tmp = df.join(df_attribute[attribute])\n",
    "    # Split data\n",
    "    X_train, y_train, X_dev, y_dev = train_dev_test_split(df_tmp, attribute)\n",
    "    # Best params\n",
    "    params = lr_best_model(X_train, y_train)\n",
    "    # Best model\n",
    "    lr = train_best_model(X_train, y_train, params)\n",
    "    # Evaluate model\n",
    "    evaluate_model(lr, X_dev, y_dev)\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15684cdf",
   "metadata": {},
   "source": [
    "## 2. Modelling - Logistic Regression\n",
    "### 2.1 Preparing training and development sets\n",
    "We split the dataset into training & development and test sets and put the test set aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8626f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dev, df_test = train_dev_test_split(df.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b7809",
   "metadata": {},
   "source": [
    "### 2.1 Evaluating different machine learning models\n",
    "We test 4 different machine learning models with proven excellent records for classification problems like this:\n",
    "- Logistic regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Support Vector Machine\n",
    "We evaluate the performance of the models by comparing the AUC and F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "954ffe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.9367088607594937\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    carnivor       0.96      0.89      0.92        27\n",
      "    herbivor       0.98      0.98      0.98        47\n",
      "     omnivor       0.57      0.80      0.67         5\n",
      "\n",
      "    accuracy                           0.94        79\n",
      "   macro avg       0.84      0.89      0.86        79\n",
      "weighted avg       0.95      0.94      0.94        79\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  1  2]\n",
      " [ 0 46  1]\n",
      " [ 1  0  4]]\n",
      "AUC Score: 0.9847013816871972\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.8987341772151899\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    carnivor       0.96      0.85      0.90        27\n",
      "    herbivor       0.98      0.94      0.96        47\n",
      "     omnivor       0.40      0.80      0.53         5\n",
      "\n",
      "    accuracy                           0.90        79\n",
      "   macro avg       0.78      0.86      0.80        79\n",
      "weighted avg       0.93      0.90      0.91        79\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23  1  3]\n",
      " [ 0 44  3]\n",
      " [ 1  0  4]]\n",
      "AUC Score: 0.9094100357176599\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9240506329113924\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    carnivor       0.93      0.93      0.93        27\n",
      "    herbivor       0.96      0.94      0.95        47\n",
      "     omnivor       0.67      0.80      0.73         5\n",
      "\n",
      "    accuracy                           0.92        79\n",
      "   macro avg       0.85      0.89      0.87        79\n",
      "weighted avg       0.93      0.92      0.93        79\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25  2  0]\n",
      " [ 1 44  2]\n",
      " [ 1  0  4]]\n",
      "AUC Score: 0.9910144203805551\n",
      "\n",
      "Model: SVM\n",
      "Accuracy: 0.8860759493670886\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    carnivor       0.85      0.85      0.85        27\n",
      "    herbivor       0.96      0.96      0.96        47\n",
      "     omnivor       0.40      0.40      0.40         5\n",
      "\n",
      "    accuracy                           0.89        79\n",
      "   macro avg       0.74      0.74      0.74        79\n",
      "weighted avg       0.89      0.89      0.89        79\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23  2  2]\n",
      " [ 1 45  1]\n",
      " [ 3  0  2]]\n",
      "AUC Score: 0.9653240460864575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_models(df, target_column, model_choices, features_start_col=12, random_state=42):\n",
    "    # Split features and target\n",
    "    X = df.iloc[:, features_start_col:]\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Define available models\n",
    "    available_models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=random_state),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=random_state),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=random_state),\n",
    "        \"SVM\": SVC(probability=True, random_state=random_state)\n",
    "    }\n",
    "    \n",
    "    # Initialize LabelBinarizer for AUC calculation\n",
    "    lb = LabelBinarizer()\n",
    "    y_dev_binarized = lb.fit_transform(y_dev)\n",
    "\n",
    "    for model_choice in model_choices:\n",
    "        model = available_models.get(model_choice)\n",
    "        if model is None:\n",
    "            print(f\"Invalid model choice: {model_choice}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Fit and evaluate the selected model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_dev)\n",
    "\n",
    "        # AUC Calculation\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_score = model.predict_proba(X_dev)\n",
    "        else:  # Use decision function if predict_proba is not available\n",
    "            y_score = model.decision_function(X_dev)\n",
    "            y_score = (y_score - y_score.min()) / (y_score.max() - y_score.min())  # Normalize\n",
    "\n",
    "        if len(lb.classes_) == 2:\n",
    "            auc_score = roc_auc_score(y_dev_binarized, y_score[:, 1])\n",
    "        else:\n",
    "            auc_score = roc_auc_score(y_dev_binarized, y_score, average='macro', multi_class='ovr')\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Model: {model_choice}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_dev, y_pred)}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_dev, y_pred))\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_dev, y_pred))\n",
    "        print(f\"AUC Score: {auc_score}\\n\")\n",
    "\n",
    "model_choices = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"SVM\"]\n",
    "evaluate_models(df=df_train_dev, target_column='Diet', model_choices=model_choices, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2632821",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "**Strengths**: High accuracy (93.67%), excellent AUC score (0.9847), and strong performance across precision, recall, and F1-score for \"carnivor\" and \"herbivor\" classes.  \n",
    "**Weaknesses**: Lower performance on the \"omnivor\" class compared to others, though still decent in the context of this problem.  \n",
    "**Why Choose**: It offers a balanced performance across most metrics, with particularly strong results for two major classes and the best overall AUC, indicating its robustness in distinguishing between classes.  \n",
    "\n",
    "#### Decision Tree\n",
    "\n",
    "**Strengths**: Reasonable accuracy (89.87%) and good precision for \"carnivor\" and \"herbivor\".  \n",
    "**Weaknesses**: The model has a lower AUC score (0.9094) compared to others and struggles with the \"omnivor\" class, indicating potential overfitting or lack of generalization.  \n",
    "**Why Choose**: Might be preferred for interpretability reasons, as decision trees are easy to understand and visualize. However, performance-wise, it's outclassed by other models here.  \n",
    "\n",
    "#### Random Forest\n",
    "\n",
    "**Strengths**: Very high AUC score (0.9910), indicating excellent capability in class separation, and solid accuracy (92.41%). It performs well across all classes, with particularly good results for handling the \"omnivor\" class.  \n",
    "**Weaknesses**: Slightly lower accuracy and performance metrics for some classes compared to Logistic Regression.  \n",
    "**Why Choose**: Offers a good trade-off between accuracy and handling of all classes, with the highest AUC score, making it very competitive, especially if the model's complexity and potential for overfitting are managed well.  \n",
    "\n",
    "#### SVM\n",
    "\n",
    "**Strengths**: Good overall accuracy (88.61%) and a decent AUC score (0.9653).  \n",
    "**Weaknesses**: Struggles more with the \"omnivor\" class than other models and has the lowest macro averages across precision, recall, and F1-score, suggesting it might not be as effective in balancing class performance.  \n",
    "**Why Choose**: Could be considered if the specific strengths of SVMs (e.g., handling high-dimensional data) are particularly relevant to the broader context of the problem.  \n",
    "\n",
    "#### Recommendation\n",
    "\n",
    "Given the metrics, Logistic Regression and Random Forest stand out as the two best candidates. Logistic Regression offers very high accuracy and a great balance across performance metrics, making it a strong choice for scenarios where interpretability and simplicity are valued alongside performance. Random Forest, on the other hand, provides the best AUC score and good performance across all classes, indicating its strength in handling a diverse set of classification scenarios, albeit at the cost of being more complex and less interpretable than Logistic Regression.\n",
    "\n",
    "If the goal is to maximize overall performance with a particular emphasis on distinguishing between classes as accurately as possible, Random Forest might be the preferable choice due to its superior AUC score. However, if you prioritize simplicity, interpretability, and still want strong performance across most metrics, Logistic Regression would be a solid choice. The final decision should consider the specific application needs, including the importance of model interpretability, computational resources, and how critical it is to accurately predict each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2267263f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.9620253164556962\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "foregut_ruminant       0.92      0.96      0.94        24\n",
      "   hindgut_colon       0.94      0.94      0.94        18\n",
      "          simple       1.00      0.97      0.99        37\n",
      "\n",
      "        accuracy                           0.96        79\n",
      "       macro avg       0.95      0.96      0.96        79\n",
      "    weighted avg       0.96      0.96      0.96        79\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23  1  0]\n",
      " [ 1 17  0]\n",
      " [ 1  0 36]]\n",
      "AUC Score: 0.9973232653560523\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9873417721518988\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "foregut_ruminant       0.96      1.00      0.98        24\n",
      "   hindgut_colon       1.00      0.94      0.97        18\n",
      "          simple       1.00      1.00      1.00        37\n",
      "\n",
      "        accuracy                           0.99        79\n",
      "       macro avg       0.99      0.98      0.98        79\n",
      "    weighted avg       0.99      0.99      0.99        79\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  0  0]\n",
      " [ 1 17  0]\n",
      " [ 0  0 37]]\n",
      "AUC Score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, let's go with LR and RF a level deeper and predict digestion\n",
    "model_choices = [\"Logistic Regression\", \"Random Forest\"]\n",
    "evaluate_models(df=df_train_dev, target_column='digestion', model_choices=model_choices, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c76f05",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "**Strengths**: Exceptional accuracy (96.20%) and an outstanding AUC score (0.9973), demonstrating its strong capability to differentiate between the digestion types. It shows excellent precision, recall, and F1-score across all categories, with \"simple\" digestion being particularly well-identified.  \n",
    "**Weaknesses**: While overall performance is high, there's a slight relative weakness in distinguishing the \"hindgut_colon\" compared to \"foregut_ruminant\" and \"simple\", as indicated by a slightly lower precision and recall.  \n",
    "**Why Choose**: Ideal for scenarios requiring a balance between interpretability and high performance. Its robustness across a broad spectrum of classes, combined with near-perfect AUC, makes it a strong candidate for applications where model understanding and justification are as important as accuracy.\n",
    "\n",
    "#### Random Forest\n",
    "\n",
    "**Strengths**: Near-perfect accuracy (98.73%) and a perfect AUC score (1.0), indicating superior performance in classifying digestion types. It showcases unmatched precision and recall, achieving perfect or near-perfect scores across all categories. Notably, it performs flawlessly in classifying \"foregut_ruminant\" and \"simple\" digestion types without any misclassification.  \n",
    "**Weaknesses**: Minimal to none, given the performance metrics. However, the slight misclassification in \"hindgut_colon\" (though very minimal) shows that no model is entirely without fault. Random Forest models also tend to be less interpretable than Logistic Regression, which might be considered a weakness in contexts requiring transparent decision-making processes.  \n",
    "**Why Choose**: The go-to model for maximizing predictive accuracy and reliability across all classes. Its perfect AUC score emphasizes its ability to distinguish between classes confidently. This model is particularly valuable in situations where the highest possible accuracy is critical, and the complexity of the model can be managed or is of lesser concern.\n",
    "\n",
    "#### Comparative Evaluation\n",
    "\n",
    "While both models perform exceptionally well, Random Forest edges out over Logistic Regression in nearly every metric, particularly in accuracy and AUC, indicating its slightly better capability in handling this specific classification task. The Random Forest model demonstrates its robustness through its adaptability and precision across all classes, making it particularly useful in scenarios where accuracy is paramount and the slight additional complexity is not a deterrent.\n",
    "\n",
    "However, Logistic Regression still offers compelling reasons for selection, particularly in use cases where model simplicity, interpretability, and easier explanation of predictions are required, alongside high performance. Its excellent performance metrics make it a viable option for many practical applications, especially when trade-offs between complexity and interpretability are considered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebfc4ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.8860759493670886\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Ailuridae       1.00      0.80      0.89         5\n",
      "     Bovidae       1.00      0.94      0.97        17\n",
      "     Canidae       0.62      0.71      0.67         7\n",
      "     Equidae       0.94      0.94      0.94        18\n",
      "     Felidae       0.90      0.86      0.88        22\n",
      "  Giraffidae       0.67      0.86      0.75         7\n",
      "     Ursidae       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.89        79\n",
      "   macro avg       0.88      0.87      0.87        79\n",
      "weighted avg       0.90      0.89      0.89        79\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 4  0  1  0  0  0  0]\n",
      " [ 0 16  0  0  0  1  0]\n",
      " [ 0  0  5  0  2  0  0]\n",
      " [ 0  0  0 17  0  1  0]\n",
      " [ 0  0  2  0 19  1  0]\n",
      " [ 0  0  0  1  0  6  0]\n",
      " [ 0  0  0  0  0  0  3]]\n",
      "AUC Score: 0.9664480543286222\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.8227848101265823\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Ailuridae       0.75      0.60      0.67         5\n",
      "     Bovidae       0.80      0.94      0.86        17\n",
      "     Canidae       0.80      0.57      0.67         7\n",
      "     Equidae       0.95      1.00      0.97        18\n",
      "     Felidae       0.83      0.91      0.87        22\n",
      "  Giraffidae       0.67      0.29      0.40         7\n",
      "     Ursidae       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.82        79\n",
      "   macro avg       0.76      0.71      0.72        79\n",
      "weighted avg       0.82      0.82      0.81        79\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0  0  2]\n",
      " [ 0 16  0  0  0  1  0]\n",
      " [ 0  0  4  0  3  0  0]\n",
      " [ 0  0  0 18  0  0  0]\n",
      " [ 1  0  1  0 20  0  0]\n",
      " [ 0  4  0  1  0  2  0]\n",
      " [ 0  0  0  0  1  0  2]]\n",
      "AUC Score: 0.9851448039005998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, let's go with LR and RF a level deeper and predict digestion\n",
    "model_choices = [\"Logistic Regression\", \"Random Forest\"]\n",
    "evaluate_models(df=df_train_dev, target_column='Familie', model_choices=model_choices, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64501bc1",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "**Strengths**: Demonstrates high precision and recall for several families, including \"Ailuridae\", \"Bovidae\", and \"Ursidae\", with perfect or near-perfect scores, suggesting a strong ability to identify these families accurately. The overall accuracy of 88.61% and an AUC score of 0.9664 indicate robust performance across the board.  \n",
    "**Weaknesses**: Lower performance for the \"Canidae\" family, indicated by a precision of 0.62 and recall of 0.71, shows some difficulty in distinguishing this family accurately compared to others. The model also shows variability in its ability to classify \"Giraffidae\" with lower precision.  \n",
    "**Why Choose**: It provides a balanced performance with a strong leaning towards accurately predicting certain families. The high overall accuracy and AUC score make it a reliable choice for applications where the specific strengths of this model align with the classification goals, particularly for distinguishing \"Ailuridae\", \"Bovidae\", and \"Ursidae\".\n",
    "\n",
    "#### Random Forest\n",
    "\n",
    "**Strengths**: Exhibits excellent precision and recall for \"Equidae\" with a 0.95 and 1.00, respectively, showing its particular strength in identifying this family. The model also demonstrates good performance for \"Felidae\".  \n",
    "**Weaknesses**: Struggles with \"Giraffidae\" and \"Ursidae\", as seen in lower recall rates and varying precision, indicating difficulty in consistently identifying these less represented families. The overall lower accuracy of 82.28% and some variability in the precision and recall across families suggest some challenges in generalization compared to Logistic Regression.  \n",
    "**Why Choose**: While it shows variability in performance across different families, its strengths in classifying \"Equidae\" and \"Felidae\" might make it a preferable choice for specific contexts requiring high accuracy in these categories. Its AUC score of 0.9851, despite a lower overall accuracy, suggests a strong capability in distinguishing between classes for certain families.\n",
    "\n",
    "#### Comparative Evaluation\n",
    "\n",
    "Logistic Regression is the more consistent performer across a broader range of families, offering higher accuracy and balanced precision and recall for most categories. Its ability to almost perfectly classify several families makes it a versatile and reliable model for general use, especially where fine distinctions between certain families are crucial.\n",
    "\n",
    "Random Forest, while presenting an unmatched capability in classifying \"Equidae\" and showing good performance for \"Felidae\", exhibits some inconsistencies across other families, notably \"Giraffidae\" and \"Ursidae\". Despite these challenges, its perfect AUC score suggests a strong underlying capability that, with further tuning or in combination with ensemble techniques, could offer competitive or superior performance in specific contexts.\n",
    "\n",
    "**Conclusion**: Choosing between Logistic Regression and Random Forest would depend on the specific classification requirements and the importance of accurately predicting certain families. Logistic Regression offers a more balanced and consistent performance across a wider array of classes, making it suitable for general purposes. In contrast, Random Forest, despite its slightly lower overall accuracy, might be preferred in scenarios where its particular strengths align with the classification objectives, supplemented by its strong capability in distinguishing between classes as evidenced by its AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a4d03",
   "metadata": {},
   "source": [
    "### 2.2 Classification of Diet\n",
    "#### 2.2.1 Herbivores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da7d43ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1.0, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best score: 0.9746031746031747\n",
      "Test score: 0.9809523809523809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.98      0.98        57\n",
      "        True       0.98      0.98      0.98        48\n",
      "\n",
      "    accuracy                           0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n",
      "Confusion Matrix:\n",
      " [[56  1]\n",
      " [ 1 47]]\n",
      "AUC: 0.9992690058479532\n"
     ]
    }
   ],
   "source": [
    "lr_herbivore = categorize_attribute(df_train_dev, 'Diet', 'herbivor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52175c96",
   "metadata": {},
   "source": [
    "#### 2.2.2 Carnivores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "281268d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1.0, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best score: 0.9523809523809523\n",
      "Test score: 0.9619047619047619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.98      0.97        60\n",
      "        True       0.98      0.93      0.95        45\n",
      "\n",
      "    accuracy                           0.96       105\n",
      "   macro avg       0.96      0.96      0.96       105\n",
      "weighted avg       0.96      0.96      0.96       105\n",
      "\n",
      "Confusion Matrix:\n",
      " [[59  1]\n",
      " [ 3 42]]\n",
      "AUC: 0.9914814814814815\n"
     ]
    }
   ],
   "source": [
    "lr_carnivore = categorize_attribute(df_train_dev, 'Diet', 'carnivor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c8154",
   "metadata": {},
   "source": [
    "#### 2.2.3 Omnivores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a6c535c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga'}\n",
      "Best score: 0.9587301587301587\n",
      "Test score: 0.9428571428571428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.96      0.97        93\n",
      "        True       0.71      0.83      0.77        12\n",
      "\n",
      "    accuracy                           0.94       105\n",
      "   macro avg       0.85      0.90      0.87       105\n",
      "weighted avg       0.95      0.94      0.94       105\n",
      "\n",
      "Confusion Matrix:\n",
      " [[89  4]\n",
      " [ 2 10]]\n",
      "AUC: 0.9767025089605735\n"
     ]
    }
   ],
   "source": [
    "lr_omnivore = categorize_attribute(df_train_dev, 'Diet', 'omnivor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155acddb",
   "metadata": {},
   "source": [
    "### 2.3 Classification of family given non-herbivores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cff4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df for non-herbivores\n",
    "df_train_dev_nh = df_train_dev[df_train_dev.Diet != 'herbivor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09789f6",
   "metadata": {},
   "source": [
    "#### 2.3.1 Canidae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5183c605",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'max_iter': 1000, 'penalty': 'none', 'solver': 'sag'}\n",
      "Best score: 0.8835294117647059\n",
      "Test score: 0.8620689655172413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.86      0.90        44\n",
      "        True       0.67      0.86      0.75        14\n",
      "\n",
      "    accuracy                           0.86        58\n",
      "   macro avg       0.81      0.86      0.83        58\n",
      "weighted avg       0.88      0.86      0.87        58\n",
      "\n",
      "Confusion Matrix:\n",
      " [[38  6]\n",
      " [ 2 12]]\n",
      "AUC: 0.9107142857142858\n"
     ]
    }
   ],
   "source": [
    "lr_canidae = categorize_attribute(df_train_dev_nh, 'Familie', 'Canidae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc5097f",
   "metadata": {},
   "source": [
    "#### 2.3.2 Felidae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa9f0a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'max_iter': 500, 'penalty': 'none', 'solver': 'sag'}\n",
      "Best score: 0.8662184873949581\n",
      "Test score: 0.8793103448275862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.90      0.89        30\n",
      "        True       0.89      0.86      0.87        28\n",
      "\n",
      "    accuracy                           0.88        58\n",
      "   macro avg       0.88      0.88      0.88        58\n",
      "weighted avg       0.88      0.88      0.88        58\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27  3]\n",
      " [ 4 24]]\n",
      "AUC: 0.9500000000000001\n"
     ]
    }
   ],
   "source": [
    "lr_felidae = categorize_attribute(df_train_dev_nh, 'Familie', 'Felidae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1abf9f",
   "metadata": {},
   "source": [
    "#### 2.3.3 Herpestidae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41ae9b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best score: 0.9420168067226891\n",
      "Test score: 0.9310344827586207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      1.00      0.96        54\n",
      "        True       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.93        58\n",
      "   macro avg       0.47      0.50      0.48        58\n",
      "weighted avg       0.87      0.93      0.90        58\n",
      "\n",
      "Confusion Matrix:\n",
      " [[54  0]\n",
      " [ 4  0]]\n",
      "AUC: 0.8194444444444444\n"
     ]
    }
   ],
   "source": [
    "lr_herpestidae = categorize_attribute(df_train_dev_nh, 'Familie', 'Herpestidae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17108d38",
   "metadata": {},
   "source": [
    "#### 2.3.4 Ursidae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27a7c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score: 0.9475630252100841\n",
      "Test score: 0.9137931034482759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.96      0.95        45\n",
      "        True       0.83      0.77      0.80        13\n",
      "\n",
      "    accuracy                           0.91        58\n",
      "   macro avg       0.88      0.86      0.87        58\n",
      "weighted avg       0.91      0.91      0.91        58\n",
      "\n",
      "Confusion Matrix:\n",
      " [[43  2]\n",
      " [ 3 10]]\n",
      "AUC: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "lr_ursidae = categorize_attribute(df_train_dev_nh, 'Familie', 'Ursidae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9833ae6",
   "metadata": {},
   "source": [
    "### 3.3 Classification by digestion for herbivores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "656bfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter train dev dataset for herbivores only\n",
    "df_herbivore = df_train_dev[df_train_dev.Diet == 'herbivor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2cd27",
   "metadata": {},
   "source": [
    "#### 3.3.1 Classification by digestion for herbivores - Foregut ruminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30fa892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1.0, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best score: 0.9928571428571429\n",
      "Test score: 0.9583333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      1.00      0.96        23\n",
      "        True       1.00      0.92      0.96        25\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.96      0.96      0.96        48\n",
      "weighted avg       0.96      0.96      0.96        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[23  0]\n",
      " [ 2 23]]\n",
      "AUC: 0.9878260869565216\n"
     ]
    }
   ],
   "source": [
    "lr_foregut_r = categorize_attribute(df_herbivore, 'digestion', 'foregut_ruminant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba02f9d",
   "metadata": {},
   "source": [
    "#### 3.3.2 Classification by digestion for herbivores - Hindgut colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15fa9c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 0.9859605911330049\n",
      "Test score: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00        31\n",
      "        True       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[31  0]\n",
      " [ 0 17]]\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "lr_hindgut_co = categorize_attribute(df_herbivore, 'digestion', 'hindgut_colon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388182d",
   "metadata": {},
   "source": [
    "#### 3.3.3 Classification by digestion for herbivores -  Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cbcac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 1.0\n",
      "Test score: 0.9791666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      1.00      0.99        42\n",
      "        True       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.98        48\n",
      "   macro avg       0.99      0.92      0.95        48\n",
      "weighted avg       0.98      0.98      0.98        48\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  0]\n",
      " [ 1  5]]\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "lr_simple = categorize_attribute(df_herbivore, 'digestion', 'simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718cf6cd",
   "metadata": {},
   "source": [
    "### 3.5 Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae7228c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_microbiome(microbiome):\n",
    "    results = []\n",
    "\n",
    "    # Initialize lists to store probabilities for AUC calculation\n",
    "    true_labels = []\n",
    "    pred_probabilities = []\n",
    "\n",
    "    # Diet categorization probabilities\n",
    "    herbivore_prob = lr_herbivore.predict_proba(microbiome)[:, 1]\n",
    "    carnivore_prob = lr_carnivore.predict_proba(microbiome)[:, 1]\n",
    "    omnivore_prob = lr_omnivore.predict_proba(microbiome)[:, 1]\n",
    "\n",
    "    true_labels.append(1 if max(h_prob, c_prob, o_prob) == h_prob else 0)\n",
    "    pred_probabilities.append(max(h_prob, c_prob, o_prob))\n",
    "\n",
    "    for idx, (h_prob, c_prob, o_prob) in enumerate(zip(herbivore_prob, carnivore_prob, omnivore_prob)):\n",
    "        # Categorize diet\n",
    "        max_diet_prob = max(h_prob, c_prob, o_prob)\n",
    "        if max_diet_prob == h_prob:\n",
    "            diet = \"herbivor\"\n",
    "            sample = microbiome.iloc[idx].to_numpy().reshape(1, -1)\n",
    "            foregut_r_prob = lr_foregut_r.predict_proba(sample)[0][1]\n",
    "            hindgut_co_prob = lr_hindgut_co.predict_proba(sample)[0][1]\n",
    "            simple_prob = lr_simple.predict_proba(sample)[0][1]\n",
    "\n",
    "            digestion_prob = {\n",
    "                \"foregut_ruminant\": foregut_r_prob,\n",
    "                \"hindgut_colon\": hindgut_co_prob,\n",
    "                \"simple\": simple_prob\n",
    "            }\n",
    "            digestion = max(digestion_prob, key=digestion_prob.get)\n",
    "            familie = None\n",
    "            probabilities = h_prob*digestion_prob[digestion]\n",
    "        elif max_diet_prob == c_prob:\n",
    "            diet = \"carnivor\"\n",
    "            digestion = \"simple\"\n",
    "\n",
    "            # Determine 'Familie' based on model probabilities\n",
    "            sample = microbiome.iloc[idx].to_numpy().reshape(1, -1)\n",
    "            canidae_prob = lr_canidae.predict_proba(sample)[0][1]\n",
    "            felidae_prob = lr_felidae.predict_proba(sample)[0][1]\n",
    "            herpestidae_prob = lr_herpestidae.predict_proba(sample)[0][1]\n",
    "            ursidae_prob = lr_ursidae.predict_proba(sample)[0][1]\n",
    "\n",
    "            familie_prob = {\n",
    "                \"Canidae\": canidae_prob,\n",
    "                \"Felidae\": felidae_prob,\n",
    "                \"Herpestidae\": herpestidae_prob,\n",
    "                \"Ursidae\": ursidae_prob,\n",
    "                \"Undefined\": 0.00000001\n",
    "            }\n",
    "            familie = max(familie_prob, key=familie_prob.get)\n",
    "            probabilities = c_prob*familie_prob[familie]\n",
    "        else:\n",
    "            diet = \"omnivor\"\n",
    "            digestion = \"simple\"\n",
    "\n",
    "            # Determine 'Familie' based on model probabilities\n",
    "            sample = microbiome.iloc[idx].to_numpy().reshape(1, -1)\n",
    "            canidae_prob = lr_canidae.predict_proba(sample)[0][1]\n",
    "            felidae_prob = lr_felidae.predict_proba(sample)[0][1]\n",
    "            herpestidae_prob = lr_herpestidae.predict_proba(sample)[0][1]\n",
    "            ursidae_prob = lr_ursidae.predict_proba(sample)[0][1]\n",
    "\n",
    "            familie_prob = {\n",
    "                \"Canidae\": canidae_prob,\n",
    "                \"Felidae\": felidae_prob,\n",
    "                \"Herpestidae\": herpestidae_prob,\n",
    "                \"Ursidae\": ursidae_prob,\n",
    "                \"Undefined\": 0.00000001\n",
    "            }\n",
    "            familie = max(familie_prob, key=familie_prob.get)\n",
    "            probabilities = o_prob*familie_prob[familie]\n",
    "\n",
    "        # Append the result with the original index\n",
    "        results.append([microbiome.index[idx], diet, digestion, familie, probabilities])\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    categorized_df = pd.DataFrame(results, columns=['Index', 'Diet_p', 'digestion_p', 'Familie_p','Probabilities_p'])\n",
    "    categorized_df.set_index('Index', inplace=True)\n",
    "\n",
    "    return categorized_df\n",
    "\n",
    "def calculate_auc_for_each_class(microbiome, label, lr_models):\n",
    "    \"\"\"\n",
    "    Calculates and prints AUC for each class against the rest.\n",
    "    \n",
    "    Parameters:\n",
    "    - microbiome: The input features for classification.\n",
    "    - lr_models: A dictionary of logistic regression models for each class.\n",
    "    \"\"\"\n",
    "    true_classes = microbiome[label] # This should be your actual labels for each sample\n",
    "    microbiome = microbiome.iloc[:,12:]\n",
    "    \n",
    "    # Assuming lr_models is a dict of {'class_name': model} pairs\n",
    "    for class_name, model in lr_models.items():\n",
    "        # Get predicted probabilities for being in the current class\n",
    "        class_prob = model.predict_proba(microbiome)[:, 1]\n",
    "        \n",
    "        # Generate binary labels: 1 for current class, 0 for all others\n",
    "        binary_labels = [1 if c == class_name else 0 for c in true_classes]\n",
    "        \n",
    "        # Calculate AUC\n",
    "        auc_score = roc_auc_score(binary_labels, class_prob)\n",
    "        print(f\"AUC for {class_name} vs. Rest: {auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e20cdb",
   "metadata": {},
   "source": [
    "### 3.6 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "258f2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = categorize_microbiome(df_test.iloc[:,12:])\n",
    "results_test = pred.join(df_test, how='left')\n",
    "results_test['Familie_p'] = results_test['Familie_p'].fillna('Unknown') # To handle incorrectly identified herbivores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8caa06b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on Diet\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    carnivor       0.90      0.84      0.87        45\n",
      "    herbivor       0.94      0.92      0.93        48\n",
      "     omnivor       0.62      0.83      0.71        12\n",
      "\n",
      "    accuracy                           0.88       105\n",
      "   macro avg       0.82      0.86      0.84       105\n",
      "weighted avg       0.89      0.88      0.88       105\n",
      "\n",
      "[[38  3  4]\n",
      " [ 2 44  2]\n",
      " [ 2  0 10]]\n",
      "AUC for herbivor vs. Rest: 0.9594298245614035\n",
      "AUC for carnivor vs. Rest: 0.9692592592592593\n",
      "AUC for omnivor vs. Rest: 0.9578853046594983\n"
     ]
    }
   ],
   "source": [
    "print('Classification report on Diet')\n",
    "print(classification_report(results_test.Diet, results_test.Diet_p))\n",
    "print(confusion_matrix(results_test.Diet, results_test.Diet_p))\n",
    "\n",
    "# AUC for Diet classification models\n",
    "lr_models = {\n",
    "    'herbivor': lr_herbivore,\n",
    "    'carnivor': lr_carnivore,\n",
    "    'omnivor': lr_omnivore\n",
    "}\n",
    "\n",
    "calculate_auc_for_each_class(df_test, 'Diet', lr_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a450e669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on Digestion for Herbivores\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "foregut_ruminant       1.00      0.96      0.98        25\n",
      "   hindgut_colon       1.00      1.00      1.00        17\n",
      "          simple       0.86      1.00      0.92         6\n",
      "\n",
      "        accuracy                           0.98        48\n",
      "       macro avg       0.95      0.99      0.97        48\n",
      "    weighted avg       0.98      0.98      0.98        48\n",
      "\n",
      "[[24  0  1]\n",
      " [ 0 17  0]\n",
      " [ 0  0  6]]\n",
      "AUC for foregut_ruminant vs. Rest: 0.965\n",
      "AUC for hindgut_colon vs. Rest: 0.9953208556149733\n",
      "AUC for simple vs. Rest: 0.9947089947089947\n"
     ]
    }
   ],
   "source": [
    "print('Classification report on Digestion for Herbivores')\n",
    "print(classification_report(results_test[results_test.Diet == 'herbivor'].digestion,\n",
    "                            results_test[results_test.Diet == 'herbivor'].digestion_p))\n",
    "print(confusion_matrix(results_test[results_test.Diet == 'herbivor'].digestion,\n",
    "                            results_test[results_test.Diet == 'herbivor'].digestion_p))\n",
    "\n",
    "# AUC for Digestion classification models\n",
    "lr_models = {\n",
    "    'foregut_ruminant': lr_foregut_r,\n",
    "    'hindgut_colon': lr_hindgut_co,\n",
    "    'simple': lr_simple\n",
    "}\n",
    "\n",
    "calculate_auc_for_each_class(df_test, 'digestion', lr_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94ff3987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on Family for Carnivores and Omnivores\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Canidae       0.88      1.00      0.93        14\n",
      "     Felidae       0.91      0.74      0.82        27\n",
      " Herpestidae       0.00      0.00      0.00         4\n",
      "     Unknown       0.00      0.00      0.00         0\n",
      "     Ursidae       0.69      0.92      0.79        12\n",
      "\n",
      "    accuracy                           0.79        57\n",
      "   macro avg       0.49      0.53      0.51        57\n",
      "weighted avg       0.79      0.79      0.78        57\n",
      "\n",
      "[[14  0  0  0  0]\n",
      " [ 1 20  0  2  4]\n",
      " [ 1  1  0  1  1]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  1  0  0 11]]\n",
      "AUC for Canidae vs. Rest: 0.5125588697017268\n",
      "AUC for Felidae vs. Rest: 0.9468186134852802\n",
      "AUC for Herpestidae vs. Rest: 0.693069306930693\n",
      "AUC for Ursidae vs. Rest: 0.9381720430107526\n"
     ]
    }
   ],
   "source": [
    "print('Classification report on Family for Carnivores and Omnivores')\n",
    "print(classification_report(results_test[results_test.Diet != 'herbivor'].Familie,\n",
    "                            results_test[results_test.Diet != 'herbivor'].Familie_p))\n",
    "print(confusion_matrix(results_test[results_test.Diet != 'herbivor'].Familie,\n",
    "                            results_test[results_test.Diet != 'herbivor'].Familie_p))\n",
    "\n",
    "# AUC for Family classification models\n",
    "lr_models = {\n",
    "    'Canidae': lr_canidae,\n",
    "    'Felidae': lr_felidae,\n",
    "    'Herpestidae': lr_herpestidae,\n",
    "    'Ursidae': lr_ursidae\n",
    "}\n",
    "\n",
    "calculate_auc_for_each_class(df_test, 'Familie', lr_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
