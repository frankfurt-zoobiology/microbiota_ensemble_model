{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3896e7b2",
   "metadata": {},
   "source": [
    "# Categorizing zoo animal species by microbiome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb1f0f",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "### 1.1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc7b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Turn only off for presentation purposes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fdb337",
   "metadata": {},
   "source": [
    "### 1.2 Data import\n",
    "Data has been preprocessed in R. We removed all animal species with less than 20 probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372916e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "df = pd.read_csv('data/data_clean.csv')\n",
    "metadata = df.iloc[:,:9].drop_duplicates().sort_values(['Familie','Gattung','Art']).reset_index(drop=True)\n",
    "metadata_familie = metadata[['Familie','Diet','digestion']].drop_duplicates().reset_index(drop=True)\n",
    "metadata_gattung = metadata[['Gattung','Diet','digestion']].drop_duplicates().reset_index(drop=True)\n",
    "# Identifying zoo and individuals from index name\n",
    "df.insert(0, 'Zoo', df['index'].str[:3])\n",
    "df.insert(1, 'AnimalID', df['index'].str[7:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3da15",
   "metadata": {},
   "source": [
    "### 1.3 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e22e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_test_split(df, y_name=\"\", test_size=0.2, random_state=42):\n",
    "    if y_name != \"\":\n",
    "        # Check if stratification is possible\n",
    "        can_stratify = df[y_name].value_counts().min() > 1\n",
    "        \n",
    "        # If stratification is possible, use it\n",
    "        if can_stratify:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size/(1-test_size), \n",
    "                random_state=random_state, stratify=df[y_name]\n",
    "            )\n",
    "        # If not, do a simple split without stratification\n",
    "        else:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size/(1-test_size), \n",
    "                random_state=random_state\n",
    "            )\n",
    "        \n",
    "        # Define input and output variables\n",
    "        X_train = train.iloc[:,12:]\n",
    "        if y_name != 'Art':\n",
    "            X_train = X_train.drop([y_name], axis=1)\n",
    "        y_train = train[y_name]\n",
    "\n",
    "        X_test = test.iloc[:,12:]\n",
    "        if y_name != 'Art':\n",
    "            X_test = X_test.drop([y_name], axis=1)\n",
    "        y_test = test[y_name]\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    else:\n",
    "        # Check if stratification is possible\n",
    "        can_stratify = df['Art'].value_counts().min() > 1\n",
    "        \n",
    "        # If stratification is possible, use it\n",
    "        if can_stratify:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size, \n",
    "                random_state=random_state, stratify=df['Art']\n",
    "            )\n",
    "        # If not, do a simple split without stratification\n",
    "        else:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_size, \n",
    "                random_state=random_state\n",
    "            )\n",
    "        \n",
    "        return train, test\n",
    "\n",
    "# One-hot encoded data\n",
    "def one_hot_encoding(df, Art):\n",
    "    # One-hot encoding of column\n",
    "    df_Art = pd.get_dummies(df.Art)\n",
    "    # Join with dummy data\n",
    "    df_tmp = df.iloc[:,:-1].join(df_Art[Art])\n",
    "    # Split data\n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = train_dev_test_split(df_tmp, Art)\n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test\n",
    "\n",
    "# Find best parameters using GridSearchCV for logistic regression\n",
    "def lr_best_model(X_train, y_train):\n",
    "    # Define multiple hyperparameter grids to search over\n",
    "    param_grids = [\n",
    "        {\n",
    "            'penalty': ['l1', 'l2'],  # l1 and l2 penalties\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'solver': ['liblinear'],  # liblinear supports l1 and l2\n",
    "            'max_iter': [100, 500, 1000],\n",
    "        },\n",
    "        {\n",
    "            'penalty': ['l2', 'none'],  # l2 and none penalties\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'solver': ['newton-cg', 'lbfgs', 'sag'],  # these solvers support l2 and none\n",
    "            'max_iter': [100, 500, 1000],\n",
    "        },\n",
    "        {\n",
    "            'penalty': ['l1', 'l2', 'none'],  # l1, l2 and none penalties\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'solver': ['saga'],  # saga supports l1, l2, and none\n",
    "            'max_iter': [100, 500, 1000],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Create a logistic regression model\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "\n",
    "    # Perform grid search over the hyperparameter grids using 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=lr,\n",
    "                               param_grid=param_grids,\n",
    "                               cv=5,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "    # Fit the grid search to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and best score\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best score: {grid_search.best_score_}\")\n",
    "    \n",
    "    return grid_search.best_params_\n",
    "\n",
    "def train_best_model(X_train, y_train, params):\n",
    "    # Create a new logistic regression model with the best hyperparameters\n",
    "    best_lr = LogisticRegression(**params, random_state=42)\n",
    "\n",
    "    # Fit the new model to the training data\n",
    "    best_lr.fit(X_train, y_train)\n",
    "    \n",
    "    return best_lr\n",
    "\n",
    "def evaluate_model(best_lr, X_dev, y_dev):\n",
    "    # Evaluate the performance of the new model on the test data\n",
    "    score = best_lr.score(X_dev, y_dev)\n",
    "    print(f\"Test score: {score}\")\n",
    "\n",
    "    # Print the results\n",
    "    y_pred = best_lr.predict(X_dev)\n",
    "    print(classification_report(y_dev, y_pred))\n",
    "\n",
    "    # Create the confusion matrix\n",
    "    cm = confusion_matrix(y_dev, y_pred)\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    \n",
    "def best_lr(df, Art):\n",
    "    # One-hot encoding\n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = one_hot_encoding(df, Art)\n",
    "    # Best params\n",
    "    params = lr_best_model(X_train, y_train)\n",
    "    # Best model\n",
    "    best_lr = train_best_model(X_train, y_train, params)\n",
    "    # Evaluate model\n",
    "    evaluate_model(best_lr, X_dev, y_dev)\n",
    "    \n",
    "    return best_lr\n",
    "\n",
    "# Trains logistic regression based on specific attribute\n",
    "def categorize_attribute(df, df_attribute, attribute):\n",
    "    # Join with dummy data\n",
    "    df_tmp = df.join(df_attribute[attribute])\n",
    "    # Split data\n",
    "    X_train, y_train, X_dev, y_dev = train_dev_test_split(df_tmp, attribute)\n",
    "    # Best params\n",
    "    params = lr_best_model(X_train, y_train)\n",
    "    # Best model\n",
    "    lr = train_best_model(X_train, y_train, params)\n",
    "    # Evaluate model\n",
    "    evaluate_model(lr, X_dev, y_dev)\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15684cdf",
   "metadata": {},
   "source": [
    "## 2. Modelling - Logistic Regression\n",
    "### 2.1 Preparing training and development sets\n",
    "We split the dataset into training & development and test sets and put the test set aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8626f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dev, df_test = train_dev_test_split(df.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322eb60",
   "metadata": {},
   "source": [
    "### 2.2 Classification by diet\n",
    "A second approach is to classify by diet first and then build up subsequent models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a4d03",
   "metadata": {},
   "source": [
    "#### 2.2.1 Herbivore vs. carnivore and omnivore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4285bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1.0, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best score: 0.9746031746031747\n",
      "Test score: 0.9809523809523809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        57\n",
      "           1       0.98      0.98      0.98        48\n",
      "\n",
      "    accuracy                           0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n",
      "Confusion Matrix:\n",
      " [[56  1]\n",
      " [ 1 47]]\n"
     ]
    }
   ],
   "source": [
    "# Add herbivore dummy\n",
    "df_train_dev['Herbivore'] = (df_train_dev['Diet'] == 'herbivor').astype(int)\n",
    "# Train and dev data\n",
    "X_train, y_train, X_dev, y_dev = train_dev_test_split(df_train_dev, 'Herbivore')\n",
    "# Best params\n",
    "params = lr_best_model(X_train, y_train)\n",
    "# Best model\n",
    "lr_herbivore = train_best_model(X_train, y_train, params)\n",
    "# Evaluate model\n",
    "evaluate_model(lr_herbivore, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57587c79",
   "metadata": {},
   "source": [
    "The results are quite good and promising to move further with this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c05ecb",
   "metadata": {},
   "source": [
    "#### 2.2.2 Carnivore vs. omnivore\n",
    "Given that we distinguished herbivores from other diets, we now want to differentiate between carnivores and omnivores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df for carnivores and omnivors\n",
    "df_carni_omni = df_train_dev[df_train_dev.Diet != 'herbivor']\n",
    "df_carni_omni = df_carni_omni.drop('Herbivore', axis=1)\n",
    "df_carni_omni['Carnivore'] = (df['Diet'] == 'carnivor').astype(int)\n",
    "# Train and dev data\n",
    "X_train, y_train, X_dev, y_dev = train_dev_test_split(df_carni_omni, 'Carnivore')\n",
    "# Best params\n",
    "params = lr_best_model(X_train, y_train)\n",
    "# Best model\n",
    "lr_carnivore = train_best_model(X_train, y_train, params)\n",
    "# Evaluate model\n",
    "evaluate_model(lr_carnivore, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5edee07",
   "metadata": {},
   "source": [
    "The results are not as good as the herbivore model but still good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155acddb",
   "metadata": {},
   "source": [
    "### 2.3 Classification of family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding of animal family\n",
    "df_family = pd.get_dummies(df_train_dev.Familie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec94700",
   "metadata": {},
   "outputs": [],
   "source": [
    "for diet in df_train_dev.Diet.unique():\n",
    "    print(2*'#'+diet+60*'#')\n",
    "    df_diet = df_train_dev[df_train_dev.Diet == diet]\n",
    "    df_family = pd.get_dummies(df_diet.Familie)\n",
    "    for family in df_diet.Familie.unique():\n",
    "        print(2*'#'+family+60*'#')\n",
    "        categorize_attribute(df_diet, df_family, family)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f685d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_attribute(df_diet, df_family, family) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9833ae6",
   "metadata": {},
   "source": [
    "### 3.3 Classification by digestion for herbivores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656bfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter train dev dataset for herbivores only\n",
    "df_herbivore = df_train_dev[df_train_dev.Diet == 'herbivor'].drop('Herbivore', axis=1)\n",
    "# One-hot encoding of digestion\n",
    "df_digestion = pd.get_dummies(df_herbivore.digestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1e4df",
   "metadata": {},
   "source": [
    "#### 3.3.1 Classification by digestion for herbivores - Foregut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2cd27",
   "metadata": {},
   "source": [
    "#### 3.3.2 Classification by digestion for herbivores - Foregut ruminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_foregut_r = categorize_attribute(df_herbivore, df_digestion, 'foregut_ruminant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4b607",
   "metadata": {},
   "source": [
    "#### 3.3.3 Classification by digestion for herbivores - Hindgut caecum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba02f9d",
   "metadata": {},
   "source": [
    "#### 3.3.4 Classification by digestion for herbivores - Hindgut colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa9c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_hindgut_co = categorize_attribute(df_herbivore, df_digestion, 'hindgut_colon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388182d",
   "metadata": {},
   "source": [
    "#### 3.3.5 Classification by digestion for herbivores -  Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbcac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_simple = categorize_attribute(df_herbivore, df_digestion, 'simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb7023",
   "metadata": {},
   "source": [
    "#### 3.3.6 Classification by digestion for herbivores -  Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def herbivore_digestion_ensemble(x):\n",
    "    x = x.astype(float)\n",
    "    res = {'foregut' : lr_foregut.predict_proba([x.values])[0][1],\n",
    "           'foregut_ruminant' : lr_foregut_r.predict_proba([x.values])[0][1],\n",
    "           'hindgut_caecum' : lr_hindgut_ca.predict_proba([x.values])[0][1],\n",
    "           'hindgut_colon' : lr_hindgut_co.predict_proba([x.values])[0][1],\n",
    "           'simple' : lr_simple.predict_proba([x.values])[0][1]\n",
    "          }\n",
    "    \n",
    "    max_key = max(res, key=lambda k: res[k])\n",
    "    \n",
    "    return max_key\n",
    "\n",
    "#df_herbivore.iloc[:,9:].apply(digestion_prediction, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c1b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_herbivore[['digestion','Familie','Diet']].groupby(['digestion','Familie']).count()#.sort_values('Diet', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63c8ef",
   "metadata": {},
   "source": [
    "### 3.4 Classification of animal family given diet and digestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671435a9",
   "metadata": {},
   "source": [
    "#### 3.4.1 Herbivore and foregut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f30735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Familie - Foregut\n",
    "df_herb_fg = df_train_dev[(df_train_dev.Diet == 'herbivor') & (df_train_dev.digestion == 'foregut')]\n",
    "# One-hot encoding of digestion\n",
    "df_herb_fg_familie = pd.get_dummies(df_herb_fg.Familie)\n",
    "\n",
    "# Funktioniert nicht, weil zu wenig Beobachtungen:\n",
    "#lr_Hippopotamidae = categorize_attribute(df_herb_fg, df_herb_fg_familie, 'Hippopotamidae')\n",
    "#lr_Macropodidae = categorize_attribute(df_herb_fg, df_herb_fg_familie, 'Macropodidae')\n",
    "#lr_Suidae = categorize_attribute(df_herb_fg, df_herb_fg_familie, 'Suidae')\n",
    "#lr_Tapiridae = categorize_attribute(df_herb_fg, df_herb_fg_familie, 'Tapiridae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba96f4",
   "metadata": {},
   "source": [
    "#### 3.4.2 Herbivore and foregut ruminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990238c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Familie - Foregut ruminant\n",
    "df_herb_fg_r = df_train_dev[(df_train_dev.Diet == 'herbivor') & (df_train_dev.digestion == 'foregut_ruminant')]\n",
    "# One-hot encoding of digestion\n",
    "df_herb_fg_r_familie = pd.get_dummies(df_herb_fg_r.Familie)\n",
    "\n",
    "# Create model for each family\n",
    "print('-' * 80 + \"\\nBovidae\\n\" + '-' * 80)\n",
    "lr_Bovidae = categorize_attribute(df_herb_fg_r, df_herb_fg_r_familie, 'Bovidae')\n",
    "#print('-' * 80 + \"\\nCamelidae\\n\" + '-' * 80)\n",
    "#lr_Camelidae = categorize_attribute(df_herb_fg_r, df_herb_fg_r_familie, 'Camelidae')\n",
    "#print('-' * 80 + \"\\nCervidae\\n\" + '-' * 80)\n",
    "#lr_Cervidae = categorize_attribute(df_herb_fg_r, df_herb_fg_r_familie, 'Cervidae')\n",
    "print('-' * 80 + \"\\nGiraffidae\\n\" + '-' * 80)\n",
    "lr_Giraffidae = categorize_attribute(df_herb_fg_r, df_herb_fg_r_familie, 'Giraffidae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d70879",
   "metadata": {},
   "source": [
    "#### 3.4.3 Herbivore and hindgut colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Familie - Hingut colon\n",
    "df_herb_hg_co = df_train_dev[(df_train_dev.Diet == 'herbivor') & (df_train_dev.digestion == 'hindgut_colon')]\n",
    "# One-hot encoding of digestion\n",
    "df_herb_hg_co_familie = pd.get_dummies(df_herb_hg_co.Familie)\n",
    "\n",
    "# Create model for each family\n",
    "#print('-' * 80 + \"\\nElephantidae\\n\" + '-' * 80)\n",
    "#lr_Elephantidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Elephantidae')\n",
    "print('-' * 80 + \"\\nEquidae\\n\" + '-' * 80)\n",
    "lr_Equidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Equidae')\n",
    "#print('-' * 80 + \"\\nPhascolarctidae\\n\" + '-' * 80)\n",
    "#lr_Phascolarctidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Phascolarctidae')\n",
    "#print('-' * 80 + \"\\nRhinocerotidae\\n\" + '-' * 80)\n",
    "#lr_Rhinocerotidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Rhinocerotidae')\n",
    "#print('-' * 80 + \"\\nVombatidae\\n\" + '-' * 80)\n",
    "#lr_Vombatidae = categorize_attribute(df_herb_hg_co, df_herb_hg_co_familie, 'Vombatidae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa86cd",
   "metadata": {},
   "source": [
    "#### 3.4.4 Herbivore and simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Familie - Simple\n",
    "df_herb_simple = df_train_dev[(df_train_dev.Diet == 'herbivor') & (df_train_dev.digestion == 'simple')]\n",
    "# One-hot encoding of digestion\n",
    "df_herb_simple_familie = pd.get_dummies(df_herb_simple.Familie)\n",
    "\n",
    "# Create model for each family\n",
    "print('-' * 80 + \"\\nAiluridae\\n\" + '-' * 80)\n",
    "lr_Ailuridae = categorize_attribute(df_herb_simple, df_herb_simple_familie, 'Ailuridae')\n",
    "print('-' * 80 + \"\\nHomininae\\n\" + '-' * 80)\n",
    "lr_Homininae = categorize_attribute(df_herb_simple, df_herb_simple_familie, 'Homininae')\n",
    "print('-' * 80 + \"\\nLemuridae\\n\" + '-' * 80)\n",
    "lr_Lemuridae = categorize_attribute(df_herb_simple, df_herb_simple_familie, 'Lemuridae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718cf6cd",
   "metadata": {},
   "source": [
    "### 3.5 Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4290a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = df.Art.loc[X_dev.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7228c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foregut_ruminant(microbiome):\n",
    "    res = {'Bovidae' : lr_Bovidae.predict_proba(microbiome)[0][1],\n",
    "           'Camelidae' : lr_Camelidae.predict_proba(microbiome)[0][1],\n",
    "           'Cervidae' : lr_Cervidae.predict_proba(microbiome)[0][1],\n",
    "           'Giraffidae' : lr_Giraffidae.predict_proba(microbiome)[0][1]}\n",
    "    \n",
    "    max_key = max(res, key=lambda k: res[k])\n",
    "    \n",
    "    return max_key\n",
    "    \n",
    "\n",
    "def categorize_microbiome(microbiome):\n",
    "    res = []\n",
    "    # First, predict if herbivore or carni-/omnivore\n",
    "    diet = lr_herbivore.predict(microbiome)\n",
    "    # Second, based on diet predict type of digestion\n",
    "    for i in range(len(diet)):\n",
    "        if diet[i] == 1:\n",
    "            digestion = herbivore_digestion_ensemble(microbiome.iloc[i])\n",
    "            res.append()\n",
    "        else:\n",
    "            res.append(metadata_familie[(metadata_familie.Diet != 'herbivor')].Familie.drop_duplicates().to_list())\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[0,9:-1].astype(float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
